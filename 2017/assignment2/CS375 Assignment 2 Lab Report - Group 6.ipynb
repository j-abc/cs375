{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS375 Assignment 2 Lab Report\n",
    "#### Group 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Task Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pymongo as pm\n",
    "import gridfs\n",
    "import cPickle\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from assignment_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model_switcher import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_model_shallow = model_switcher(model_name = 'shallow_bottle',\n",
    "                          data_name = 'cifar10',\n",
    "                          loss_name = 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collname': 'shallow_bottle_default',\n",
       " 'data_name': 'cifar10',\n",
       " 'dbname': 'cifar10',\n",
       " 'exp_fn': <class experiments.cifar10 at 0x7f84a2d98120>,\n",
       " 'exp_id': '',\n",
       " 'layers': ['conv1', 'deconv1'],\n",
       " 'loss_fn': <function losses.autoencoder_loss>,\n",
       " 'loss_name': 'default',\n",
       " 'model_fn': <function models.shallow_bottle>,\n",
       " 'model_name': 'shallow_bottle',\n",
       " 'test_id': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(my_model_shallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v_list = ['V0V3V6', 'V6']\n",
    "#target_layers = ['pool1', 'conv2', 'conv3', 'conv4', 'conv5', 'pool5', 'fc6', 'fc7']\n",
    "#step_list = [90000, 150000, 240000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['localhost:24444'], document_class=dict, tz_aware=False, connect=True), u'cifar10'), u'shallow_bottle_default.files')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'testrun',\n",
       " u'testrun2',\n",
       " u'stridefix2',\n",
       " u'stridefix3',\n",
       " u'stridefix4',\n",
       " u'stride2',\n",
       " u'stridebig',\n",
       " u'stridebig4',\n",
       " u'newstride',\n",
       " u'newstride2',\n",
       " u'newstride3',\n",
       " u'omgitworks2',\n",
       " u'omgitworks5',\n",
       " u'omgitworks9',\n",
       " u'ha',\n",
       " u'ha2',\n",
       " u'ha4',\n",
       " u'ha5',\n",
       " u'ha6',\n",
       " u'ha7',\n",
       " u'ha8',\n",
       " u'nov1',\n",
       " u'nov2',\n",
       " u'nov3',\n",
       " u'n4',\n",
       " u'nov4',\n",
       " u'nov5',\n",
       " u'test_nov5',\n",
       " u'dec',\n",
       " u'steph']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = p_get_coll(vars(my_model_shallow)['collname'], vars(my_model_shallow)['dbname'])\n",
    "print(coll)\n",
    "\n",
    "coll.distinct('exp_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training curve\n",
    "To see the training curve for the experiment, we pull the training loss and plot it, along with a smoothed version of the training loss obtained by convolving the loss with a boxcar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Double check this. Bit hacky\n",
    "\n",
    "print(coll.distinct('exp_id')[-2])\n",
    "texp_id = coll.distinct('exp_id')[-2]\n",
    "print(texp_id)\n",
    "p22_training(texp_id,coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texp_id = coll.distinct('exp_id')[-2]\n",
    "print(texp_id)\n",
    "p22_training(texp_id,coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_loss, img_inputs, img_prediction = get_validation_data(texp_id, coll, 20)\n",
    "plot_l2_loss(l2_loss, texp_id)\n",
    "\n",
    "np_inputs = np.array(img_inputs).transpose([0,2,3,4,1])\n",
    "np_prediction = np.array(img_prediction).transpose([0,2,3,4,1])\n",
    "my_shape = np_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_row(in_row, num_show = None):\n",
    "    if num_show is None:\n",
    "        num_show = len(in_row)\n",
    "    fig = figure(figsize = [20, 6])\n",
    "    for i in range(num_show):\n",
    "        a = fig.add_subplot(1,num_show, i+1)\n",
    "        a.get_xaxis().set_visible(False)\n",
    "        a.get_yaxis().set_visible(False)\n",
    "        imshow(in_row[:,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_row(np_inputs[-1,:].squeeze(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_row(np_prediction[-1,:].squeeze(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Representational Similararity Analysis (RSA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nov5\n",
      "1\n",
      "valid_1000_V6\n",
      "1000 1\n"
     ]
    }
   ],
   "source": [
    "#data = {}\n",
    "#for iv in v_list:\n",
    "    #for istep in step_list:\n",
    "\n",
    "data_exp_id = coll.distinct('exp_id')[-3]\n",
    "print(data_exp_id)\n",
    "data = p_get_data_list(coll, vars(my_model_shallow)['collname'], 1, 1, data_exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the RDM results\n",
    "\n",
    "We will start with visualizing the RDMs we computed for each layer and the IT neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step = 2000\n",
    "plot_rdms(data, vars(my_model_shallow)['layers'], step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the categorization results\n",
    "\n",
    "Now let's visualize the results of the categorization and within categorization test we performed for each layer. Describe what you see.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_categorization_results(data, vars(my_model_shallow)['layers'], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_categorization_results(data, vars(my_model_shallow)['layers'], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['Animals', 'Boats', 'Cars', 'Chairs', 'Faces', 'Fruits', 'Planes', 'Tables']\n",
    "for category in categories:\n",
    "    plot_categorization_results(data, vars(my_model_shallow)['layers'], step, category=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "categories = ['Animals', 'Boats', 'Cars', 'Chairs', 'Faces', 'Fruits', 'Planes', 'Tables']\n",
    "for category in categories:\n",
    "    for istep in step_list:\n",
    "        plot_categorization_results(data[('V0V3V6',istep)], target_layers, istep, category=category)\n",
    "        \"\"\"\n",
    "#TODO Add the V0V3V6 back in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous estimation results\n",
    "We regress our activations against the 'ty' continuous variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Continuous Estimation Task for ty \\n\")\n",
    "for layer in vars(my_model_shallow)['layers']:\n",
    "    print('layer:' + layer)\n",
    "    print(data['continuous_' + layer])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Neural Response Regression\n",
    "\n",
    "We will now display the results of the regression test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'deconv1']\n",
      "[u'continuous_deconv1', u'rdm_deconv1', u'spearman_corrcoef_conv1', u'within_categorization_deconv1', u'categorization_conv1', u'it_regression_conv1', u'conv1_kernel', u'continuous_conv1', u'spearman_corrcoef_deconv1', u'rdm_conv1', u'it_regression_deconv1', u'categorization_deconv1', u'rdm_it', u'within_categorization_conv1']\n",
      "nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-332ded487317>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtarget_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model_shallow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mplot_regression_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-332ded487317>\u001b[0m in \u001b[0;36mplot_regression_results\u001b[1;34m(data, target_layers, step)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'it_regression_conv1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'layer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'noise_corrected_multi_rsquared_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "# TODO Fix this, get response from Damian\n",
    "#plot_regression_results(data, target_layers, step)\n",
    "\n",
    "#step = validation_data[-1]['step']\n",
    "\n",
    "def plot_regression_results(data, target_layers, step):\n",
    "    \"\"\"\n",
    "    Prints out the noise corrected multi rsquared loss for each layer.\n",
    "    \n",
    "    You will need to EDIT this function.\n",
    "    \"\"\"\n",
    "    for layer in target_layers:\n",
    "            k = 'it_regression_' + layer\n",
    "            print(data.keys())\n",
    "            print(data['it_regression_conv1'])\n",
    "            print('step', step, 'layer', layer, 1 - data[k]['noise_corrected_multi_rsquared_loss'])\n",
    "        \n",
    "        \n",
    "step = 1\n",
    "target_layers = vars(my_model_shallow)['layers']\n",
    "print(target_layers)\n",
    "plot_regression_results(data, target_layers, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : ADD THIS BACK IN !!!\n",
    "#for istep in step_list:\n",
    "#    plot_regression_results(data[('V0V3V6',istep)], target_layers, istep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Filter Visualization Evaluations\n",
    "\n",
    "Lastly, we will plot the conv1 filter kernels. \n",
    "\n",
    "###TODO THIS SHOULD BE FOR EACH TRAINING TIMEPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conv1_kernels(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Evaluation of the unsupervised models on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_classification():\n",
    "    autoencoders = [[1,2,3,6], [3,50,70,80], [2,7,8,11], [2,3,6,7], [1,1,2,3], [1,3,4,6], \n",
    "                 [3,5,6,7], [4,5,6,7], [9,60,75,86]]\n",
    "    autoencoder_legend = ['shallow_bottleneck_cifar10', 'pooled_bottleneck_cifar10', \n",
    "                          'sparse_shallow_bottleneck_cifar10', 'sparce_pooled_cifar10',\n",
    "                        'deem_symmetric_cifar10', 'vae_cifar10', 'colorful_cifar10', \n",
    "                          'shallow_bottleneck_imagenet', 'colorful_imagenet']\n",
    "    x = range(0, len(autoencoders[0]))\n",
    "\n",
    "    for autoencoder in autoencoders:\n",
    "        plt.plot(x, autoencoder)\n",
    "        #plt.plot(len(autoencoder), autoencoder)\n",
    "\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Top-1 Class Accuracy (%)')\n",
    "    plt.title(\"Linear Classification\")\n",
    "    plt.ylim([0,100])\n",
    "    plt.legend(autoencoder_legend, loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "linear_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
