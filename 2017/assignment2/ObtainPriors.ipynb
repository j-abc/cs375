{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dataprovider import CIFAR10DataProvider\n",
    "from tfutils.data import get_queue\n",
    "from color_utils import preprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "data_params = {\n",
    "                # Cifar 10 data provider arguments\n",
    "                'func': CIFAR10DataProvider,\n",
    "                'data_path': '/datasets/cifar10/tfrecords',\n",
    "                'group': 'train',\n",
    "                'crop_size': 24,\n",
    "                # TFRecords (super class) data provider arguments\n",
    "                'file_pattern': 'train*.tfrecords',\n",
    "                'batch_size': batch_size,\n",
    "                'shuffle': False,\n",
    "                'shuffle_seed': 6,\n",
    "                'n_threads': 4,\n",
    "            }\n",
    "\n",
    "queue_params = {\n",
    "                'queue_type': 'random',\n",
    "                'batch_size': batch_size,\n",
    "                'seed': 6,\n",
    "                'capacity': batch_size * 10,\n",
    "                'min_after_dequeue': batch_size * 5\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(func, queue_params=None, **data_params):\n",
    "    data_provider = func(**data_params)\n",
    "    input_ops = data_provider.init_ops()\n",
    "    assert len(input_ops) == data_params['n_threads'], (len(input_ops), data_params['n_threads'])\n",
    "    assert len(input_ops) > 0, len(input_ops)\n",
    "    batch_size = data_params['batch_size']\n",
    "    data_params['func'] = func\n",
    "    enqueue_ops = []\n",
    "    queue = get_queue(input_ops[0], shape_flag=batch_size!=1, **queue_params)\n",
    "    for input_op in input_ops:\n",
    "        # enqueue_ops.append(queue.enqueue_many(input_op))\n",
    "        if batch_size == 1:\n",
    "            enqueue_ops.append(queue.enqueue(input_op))\n",
    "        else:\n",
    "            enqueue_ops.append(queue.enqueue_many(input_op))\n",
    "    tf.train.queue_runner.add_queue_runner(tf.train.queue_runner.QueueRunner(queue,\n",
    "                                                                             enqueue_ops))\n",
    "    if queue_params['batch_size'] == 1:\n",
    "        inputs = queue.dequeue()\n",
    "    else:\n",
    "        inputs = queue.dequeue_many(queue_params['batch_size'])\n",
    "    return data_params, [queue], inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:Using all metadata from saved source\n"
     ]
    }
   ],
   "source": [
    "data_params, [queue], inputs = get_data(queue_params=queue_params, **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_l, gt_ab_313, prior_boost_nongray = tf.py_func(preprocess, [inputs['images']], [tf.float32,tf.float32,tf.float32])\n",
    "gt_ab_313.set_shape(inputs['images'].get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'PyFunc_8:1' shape=(256, 24, 24, 3) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_ab_313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    a = inputs['images'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.data_flow_ops.RandomShuffleQueue at 0x7f29e16a5410>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
